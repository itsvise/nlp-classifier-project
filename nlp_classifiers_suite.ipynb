{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpjc3J_96TVE"
      },
      "source": [
        "**TEXT CLASSIFICATION PROJECT:**\n",
        "(The project is divided into 3 classifiers)\n",
        "1. Sentiment Classifier\n",
        "2. Spam Email Classifier\n",
        "3. Text Summarization\n",
        "\n",
        "**The project is inspired by what I did in the Udemy course \"Natural Language Processing\" by ProfessionAI.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA9h2N8s5PFT"
      },
      "source": [
        "1. **SENTIMENT CLASSIFICATION** (sentiment analysis), the model that will try to understand if a sentence is positive or negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_6SEU786xp3"
      },
      "source": [
        "First of all, you need to import the dataset on which the model is to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCgEKsKz4MuN"
      },
      "outputs": [],
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2HWbKntCHJX"
      },
      "outputs": [],
      "source": [
        "# extracting the compressed file\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq8xevbt691K"
      },
      "source": [
        "Creating a function to read all reviews from all files and then return them together with the corresponding target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2Rzemv14-E8"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def get_xy(files_path, labels=[\"pos\",\"neg\"]):\n",
        "\n",
        "\n",
        "    label_map = {labels[0]:1, labels[1]:0}\n",
        "\n",
        "    reviews = []\n",
        "    y = []\n",
        "\n",
        "    for label in labels:\n",
        "      path = files_path+label\n",
        "      for file in listdir(path):\n",
        "        review_file = open(path+\"/\"+file)\n",
        "        review = review_file.read()\n",
        "\n",
        "        reviews.append(review)\n",
        "        y.append(label_map[label])\n",
        "\n",
        "    # sklearn's shuffle function allows us to\n",
        "    # mix multiple arrays in the same way\n",
        "\n",
        "    reviews, y = shuffle(reviews,y)\n",
        "\n",
        "    return(reviews,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJRxrwJ47olf"
      },
      "source": [
        "Using the function to get reviews and targeting in two lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyfcFmES5Cuq"
      },
      "outputs": [],
      "source": [
        "reviews_train, y_train = get_xy(\"aclImdb/train/\")\n",
        "reviews_test, y_test = get_xy(\"aclImdb/test/\")\n",
        "\n",
        "print(\"First review of the test set\")\n",
        "print(reviews_test[0])\n",
        "print(\"Sentiment: %d\" % y_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLCf60g17rJ2"
      },
      "source": [
        "Coding of reviews (\"bag of words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ikhVxz75FXj"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer(max_features=5000)\n",
        "\n",
        "bow_train = bow.fit_transform(reviews_train)\n",
        "bow_test = bow.transform(reviews_test)\n",
        "\n",
        "X_train = bow_train.toarray()\n",
        "X_test = bow_test.toarray()\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46vTioaPJyAk"
      },
      "source": [
        "Standardization of created arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x59TpIj5JJL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x7ed_mB7yFj"
      },
      "source": [
        "Model creation and training using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o9zIVGSJw3C"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=0.001)\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvS3lx4B728R"
      },
      "source": [
        "Prediction and verification of the result using two parameters that measure the model's accuracy:\n",
        "\n",
        "log loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L74_RlEiC_hC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "train_pred = lr.predict(X_train)\n",
        "train_pred_proba = lr.predict_proba(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "train_loss = log_loss(y_train, train_pred_proba)\n",
        "\n",
        "test_pred = lr.predict(X_test)\n",
        "test_pred_proba = lr.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "test_loss = log_loss(y_test, test_pred_proba)\n",
        "\n",
        "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss))\n",
        "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8oZd3XCFOGK"
      },
      "source": [
        "the model is quite accurate (94% on training data and 87% on testing data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7GLHZ-hLVop"
      },
      "source": [
        "**-> MODEL TEST** (Sentiment analysis [positive or negative])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Dbf5cPLWGZ"
      },
      "outputs": [],
      "source": [
        "# FIRST REVIEW TO BE CLASSIFIED (POSITIVE)\n",
        "review = \"This is the best movie I've ever seen\"\n",
        "prediction = lr.predict(bow.transform([review]))\n",
        "if prediction[0] == 0: # if negative model returns 0\n",
        "  print(\"La recensione è negativa\")\n",
        "else: # otherwise it returns 1\n",
        "  print(\"La recensione è positiva\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOBVqS-4LgOe"
      },
      "outputs": [],
      "source": [
        "# SECOND REVIEW TO BE CLASSIFIED (NEGATIVE)\n",
        "review = \"This is the worst movie I've ever seen\"\n",
        "prediction = lr.predict(bow.transform([review]))\n",
        "if prediction[0] == 0:\n",
        "  print(\"The review is negative\")\n",
        "else:\n",
        "  print(\"The review is positive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Knxh5UsO7Mp"
      },
      "source": [
        "-> the model successfully recognized which review was positive and which was negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH7rS2Vz6HO8"
      },
      "source": [
        "2. **EMAIL SPAM CLASSIFICATION** (spam classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePmdCB5N8obb"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7dCIzFA8nzj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qLycyzp8rsk"
      },
      "source": [
        "Reading the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54O2RDSO8w5Z"
      },
      "outputs": [],
      "source": [
        "spam = pd.read_csv('data/spam.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUncB39AB301"
      },
      "outputs": [],
      "source": [
        "spam.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nSU5Oz3hEgxb"
      },
      "outputs": [],
      "source": [
        "# @title v1\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "spam.groupby('v1').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNY7Ewg81uJ"
      },
      "source": [
        "Preparing the training dataset by creating labels and arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GOugvBe81ip"
      },
      "outputs": [],
      "source": [
        "z = spam['v2'] # v2 = email text\n",
        "y = spam[\"v1\"] # v1 = label (label): spam or not spam (ham)\n",
        "z_train, z_test,y_train, y_test = train_test_split(z,y,test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPXddF9E9NiR"
      },
      "source": [
        "\"Tokenization\": consists of dividing a text into smaller entities, called tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y73wZfh9OBX"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()\n",
        "features = cv.fit_transform(z_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBFEHvsd9RGY"
      },
      "source": [
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i6bfBIp9RXV"
      },
      "outputs": [],
      "source": [
        "model = svm.SVC()\n",
        "model.fit(features,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg8zlIby9SkY"
      },
      "source": [
        "Verification on test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOAdvn-v8j_Z"
      },
      "outputs": [],
      "source": [
        "features_test = cv.transform(z_test)\n",
        "print(model.score(features_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G-1CbfBFKrX"
      },
      "source": [
        "the model is very accurate (98%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g250drMfLlL4"
      },
      "source": [
        "**-> MODEL TEST** (Classifying an email [spam or not])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSBmSJzbLlcL"
      },
      "outputs": [],
      "source": [
        "# TEST ON A SPAM EMAIL\n",
        "email = [\"URGENT! You have won a 1 week FREE membership in our å£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"]\n",
        "feature_test = cv.transform(email)\n",
        "result = model.predict(feature_test)\n",
        "print(f\"The email is {result[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxG4wQ1xOC0f"
      },
      "outputs": [],
      "source": [
        "# TEST ON A NON-SPAM EMAIL (HAM)\n",
        "email = [\"Please don't text me anymore. I have nothing else to say.\"]\n",
        "feature_test = cv.transform(email)\n",
        "result = model.predict(feature_test)\n",
        "print(f\"The mail is {result[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcB-02XOO0li"
      },
      "source": [
        "-> the model successfully recognized spam mail and non-spam mail (ham)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WasVfbIL-H_t"
      },
      "source": [
        "3. **SUMMARIZE A TEXT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukILNdY5AqDD"
      },
      "source": [
        "Importing the article to be summarized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2WEkgddFVyT"
      },
      "outputs": [],
      "source": [
        "!pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqEtg99iAv2J"
      },
      "outputs": [],
      "source": [
        "from newspaper import Article\n",
        "from newspaper import Config\n",
        "\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
        "config = Config()\n",
        "config.browser_user_agent = user_agent\n",
        "page = Article(\"https://www.sciencedaily.com/releases/2021/08/210811162816.htm\", config=config)\n",
        "page.download()\n",
        "page.parse()\n",
        "print(page.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8UjIgIq_Qrv"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB6-7FTp_QSF"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYWoGvRH_TTf"
      },
      "source": [
        "Loading the model from the spaCy library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1mJ01cE_Wio"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvKcFOvJ_yCy"
      },
      "source": [
        "Text encoding (the spaCy library does most of the work automatically)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_0iWS_v_5df"
      },
      "outputs": [],
      "source": [
        "doc= nlp(page.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBsnXL5P_5_W"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs10TvtM_6R4"
      },
      "outputs": [],
      "source": [
        "tokens=[token.text for token in doc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVKNqaUD_-4U"
      },
      "source": [
        "Coding of text corpus words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGbqa0ioAI0D"
      },
      "outputs": [],
      "source": [
        "word_frequencies={}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in list(STOP_WORDS):\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequencies.keys():\n",
        "        word_frequencies[word.text] = 1\n",
        "      else:\n",
        "        word_frequencies[word.text] += 1\n",
        "max_frequency=max(word_frequencies.values())\n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word]=word_frequencies[word]/max_frequency\n",
        "sentence_tokens= [sent for sent in doc.sents]\n",
        "sentence_scores = {}\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent not in sentence_scores.keys():\n",
        "        sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "        sentence_scores[sent]+=word_frequencies[word.text.lower()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-x1fTtiBDni"
      },
      "source": [
        "per = percentage of the sentences in the article you want to extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLEWaHWHBBwy"
      },
      "outputs": [],
      "source": [
        "per = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGhKynhDGgtg"
      },
      "outputs": [],
      "source": [
        "select_length=int(len(sentence_tokens)*per)\n",
        "summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
        "final_summary=[word.text for word in summary]\n",
        "summary=''.join(final_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWfQxdALNhl"
      },
      "source": [
        "**-> Model Test** (Summarizing a Text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXkvp4Tv-ic2"
      },
      "outputs": [],
      "source": [
        "print(summary.replace(\",\", \"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUwwV-54PZBm"
      },
      "source": [
        "-> the article has been successfully summarized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhYTZV4VQx3j"
      },
      "source": [
        "**TEST MODELS VIA A UI CREATED USING THE STREAMLIT LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYxHbedXQxi3"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf-EpIgkUbhf"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "dump(lr, 'sent_classifier.sav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mWGK3dKVGJ8"
      },
      "outputs": [],
      "source": [
        "dump(model, 'spam_classifier.sav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl5gnW8sO4HC"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from joblib import load\n",
        "import spacy\n",
        "from io import StringIO\n",
        "from transformers import pipeline\n",
        "st.set_page_config(page_title=\"ThreeTools Algo\")\n",
        "\n",
        "@st.cache_resource\n",
        "def sent_load():\n",
        "  return load('/content/sent_classifier.sav')\n",
        "@st.cache_resource\n",
        "def spam_load():\n",
        "  return load('/content/spam_classifier.sav')\n",
        "@st.cache_resource\n",
        "def summ_load():\n",
        "  return spacy.load('en_core_web_sm')\n",
        "\n",
        "sent_classifier = sent_load()\n",
        "spam_classifier = spam_load()\n",
        "nlp = summ_load()\n",
        "\n",
        "def summarize(text, per):\n",
        "  doc=nlp(text)\n",
        "  tokens=[token.text for token in doc]\n",
        "  word_frequencies={}\n",
        "  for word in doc:\n",
        "    if word.text.lower() not in list(STOP_WORDS):\n",
        "      if word.text.lower() not in punctuation:\n",
        "        if word.text not in word_frequencies.keys():\n",
        "          word_frequencies[word.text] = 1\n",
        "        else:\n",
        "          word_frequencies[word.text] += 1\n",
        "  max_frequency=max(word_frequencies.values())\n",
        "  for word in word_frequencies.keys():\n",
        "    word_frequencies[word]=word_frequencies[word]/max_frequency\n",
        "  sentence_tokens= [sent for sent in doc.sents]\n",
        "  sentence_scores = {}\n",
        "  for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "      if word.text.lower() in word_frequencies.keys():\n",
        "        if sent not in sentence_scores.keys():\n",
        "          sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
        "        else:\n",
        "          sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
        "  select_length=int(len(sentence_tokens)*per)\n",
        "  summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
        "  final_summary=[word.text for word in summary]\n",
        "  summary=''.join(final_summary)\n",
        "  return summary\n",
        "\n",
        "\n",
        "file_boolean = False\n",
        "string_data = str()\n",
        "text = str()\n",
        "\n",
        "\n",
        "with st.sidebar:\n",
        "  with st.container(height=60, border=False):\n",
        "    st.title(\"Functions:\")\n",
        "\n",
        "  with st.container(height=70, border=False):\n",
        "    but1 = st.button(\"Emotion & Sentiment Analysis\", use_container_width=True)\n",
        "  with st.container(height=50, border=False):\n",
        "    but2 = st.button(\"SMS & Email Spam Classification\", use_container_width=True)\n",
        "  with st.container(height=40, border=False):\n",
        "    but3 = st.button(\"Summarizer\", use_container_width=True)\n",
        "\n",
        "with st.container(height=220, border=False):\n",
        "  col1, col2 = st.columns([3, 2])\n",
        "\n",
        "  with col1:\n",
        "    st.title(\"ThreeTools Algorithm\")\n",
        "\n",
        "  with col2:\n",
        "    uploaded_file = st.file_uploader(label=\"UPLOADER (Upload a .txt file), for Summarization\", type=['txt'])\n",
        "    if uploaded_file is not None:\n",
        "      stringio = StringIO(uploaded_file.getvalue().decode(\"utf-8\"))\n",
        "      #st.write(stringio)\n",
        "\n",
        "      string_data = stringio.read()\n",
        "      #print(string_data)\n",
        "\n",
        "      file_boolean = True\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state.keys():\n",
        "  st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Hi, how can I help you?\"}]\n",
        "  print(st.session_state.messages)\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "  with st.chat_message(message[\"role\"]):\n",
        "    st.write(message[\"content\"])\n",
        "\n",
        "\n",
        "if prompt := st.chat_input(\"Write the sentence to classify or upload it from the uploader\"):\n",
        "  st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "  with st.chat_message(\"user\"):\n",
        "    text = prompt\n",
        "    st.write(prompt)\n",
        "\n",
        "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
        "  with st.chat_message(\"assistant\"):\n",
        "    with st.spinner(\"Loading...\"):\n",
        "      if but1:\n",
        "        try:\n",
        "          prediction = sent_classifier.predict(bow.transform([text]))\n",
        "          if prediction[0] == 0: # if negative model returns 0\n",
        "            print(\"The review is negative\")\n",
        "          else: # otherwise it returns 1\n",
        "            print(\"The review is positive\")\n",
        "        except:\n",
        "          st.write(\"Something went wrong, please try again\")\n",
        "      if but2:\n",
        "        try:\n",
        "          # TEST ON A SPAM EMAIL\n",
        "          email = [text]\n",
        "          feature_test = cv.transform(email)\n",
        "          result = spam_classifier.predict(feature_test)\n",
        "          print(f\"The email is {result[0]}\")\n",
        "        except:\n",
        "          st.write(\"Something went wrong, please try again\")\n",
        "      if but3:\n",
        "        try:\n",
        "          print(summarize(string_data, 0.05).replace(\",\",\"\\n\"))\n",
        "        except:\n",
        "          st.write(\"Something went wrong, please try uploading the \" \"text to summarize in the UPLOADER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3-r6Y6RRBCu"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8h8atUZRBcl"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
